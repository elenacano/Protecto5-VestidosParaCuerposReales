# Vestidos para Cuerpos Reales ğŸ‘—

![DescripciÃ³n de la imagen](imagenes/portada.png)

# ğŸ’¡ IntroducciÃ³n al proyecto 

Hace unos meses comencÃ© con muchisima ilusiÃ³n la busqueda del vestido perfecto para mi graduaciÃ³n, sin embargo, tras ojear unas cuÃ¡ntas webs y visitar la mayorÃ­a de las tiendas de mi ciudad me di cuenta de algo, o los fabricantes se habÃ­an olvidado de mi talla o no encajaba en los patrones de la moda normativa. Me considero una mujer dentro de la media espaÃ±ola, ni muy alta ni muy baja, ni muy delgada ni muy gorda, simplemnete en la media, o lo que yo pensaba que era la media. Por lo que investiguÃ© un poco quÃ© estaba pasando con las tallas y descubrÃ­ que no estaba sola, que miles de mujeres se encontraban en la misma situaciÃ³n que yo. Me leÃ­ numerosos artÃ­culo hablando del tema, todos mencionaban una misma fuente, la Asecom (La AsociaciÃ³n de empresas de confecciÃ³n y moda de la comunidad de Madrid), la cual realizÃ³ un estudio en el que asegura que las tallas 42 y 44 son las que mÃ¡s se venden en EspaÃ±a, pese a que los escaparates no muestran precisamente a maniquÃ­es con dichas medidas.

Finalmente encontrÃ© mi vestido, pero me costÃ³. Por lo que unos meses mÃ¡s tarde y ya con las herramientas y conocimientos necesarios planteo este proyecto abordando un problema real: **Â¿Son los vestidos de hoy para las mujeres del hoy?**

Se inicia este proyecto a pequeÃ±a escala, analizando nueve de las marcas que visitÃ© hace unos meses en busca de vestido las cuales son: Mango, Forever21, Ghospell, Jaded Rose, Love Triangle, NA-KD, Vero Moda, Natural by Lila y Ladypipa. Siendo estas tiendas muy diversas a pqueÃ±as y gran escala tanto espaÃ±olas como europeas o americanas.


# ğŸ¯ Objetivo 

El objetivo fundamental entorno al cual se desarrolla este proyecto consiste en descubrir si las marcas objeto de nuestro estudio ofrecen diversidad de tallas y suficiente oferta de tallas L y XL, las cuales son las mÃ¡s consumidas en EspaÃ±a. Para ello almacenaremos todos los datos recabados y observaremos y analizaremos las siguientes cuestiones:

- La ditribuciÃ³n de vestidos por marca.
- La distribuciÃ³n de prendas por talla para cada marca.
- El precio medio y mediano para los vestidos de cada marca.
- El precio medio y mediano por tallas.
- El porcentaje de prendas por tallas para distintos tipos de vestidos.
- La distribuciÃ³n de vestidos por tallas.

AdemÃ¡s, de la marca Forever21 hemos conseguido obtener el stock para cada vestido y talla por lo que tambiÃ©n serÃ¡n analizados estos datos.

# ğŸ“ Estructura

- El proyecto se ha estructurado en una primera fase de extracciÃ³n de datos. Los datos se han obtenido mediante APIs y scraping de dos pÃ¡ginas web. Las APIs son: [Asos](https://rapidapi.com/DataCrawler/api/asos10) y [Forever21](https://rapidapi.com/apidojo/api/forever21) y las pÃ¡ginas web: [NaturalByLila](https://naturalbylila.com/) y [Ladypipa](https://ladypipa.com/). 

    - La obtenciÃ³n de informaciÃ³n de las APIs se ha llevado a cabo en los notebooks 1 y 2 que se pueden encontrar en la carpeta `notebooks` apoyandose en el archivo de `funciones_api.py` de la carpeta `src`. Los datos extraidos han sido almacenados en la carpeta `datos` dentro de `api_asos` y `api_forever21`.

    - El scraping de las webs se puede encontrar en los notebooks `3-scraping_lila.ipynb` y `4-scraping_ladypipa.ipynb` y las funciones de apoyo en la carpeta `src` en el archivo `funciones_craping.py`. 

- Una vez etraidos todos los datos pasamos a la segunda fase de la ETL que es la transformaciÃ³n y limpieza, llevada a cabo en el notebook `5-limpieza.iynb`. En esta fase limpiamos las columnas de cada dataframe aÃ±adiendo nuevas columnas o quitando alguna existente y normalizando los datos para poder unificar todos los datos obtenidos en la primera fase.

- El Ãºltimo paso es la creaciÃ³n y carga de los datos en una base de datos SQL, este paso se ejecuta en el notebook `6-creacion_insercion_bbdd.ipynb` apoyandose en las funciones del archivo `funciones_bbdd.py` y ``queries.py`. Se crea la base de datos, las tablas y se realizan las consultas necesarias para insertar todos los datos en nuestra base de datos. 

- Finamente, pasamos a la fase del anÃ¡lisis mediante consultas SQL. En esta fase extraeremos la informaciÃ³n relevante para analizar las propuestas planteadas como onjetivo y mostrar grÃ¡ficas para observar de una forma mÃ¡s visula los resultados. Toda esta informaciÃ³n se puede encontrar en el notebook `7-analisis.ipynb` apoyado en las funciones de `funciones_analisis.py`.

â”œâ”€â”€ datos â”‚ â”œâ”€â”€ api_asos â”‚ â”‚ â”œâ”€â”€ df_asos.csv â”‚ â”‚ â”œâ”€â”€ Ghospell â”‚ â”‚ â”œâ”€â”€ JadedRose â”‚ â”‚ â”‚ â””â”€â”€ vestidos_JadedRose.json â”‚ â”‚ â”œâ”€â”€ Jarlo â”‚ â”‚ â”œâ”€â”€ LoveTriangle â”‚ â”‚ â”œâ”€â”€ Mango â”‚ â”‚ â”œâ”€â”€ NAKD â”‚ â”‚ â””â”€â”€ VeroModa â”‚ â””â”€â”€ api_forever21 â”‚ â””â”€â”€ dataframes â”‚ â”œâ”€â”€ df_asos.csv â”‚ â”œâ”€â”€ df_bylila.csv â”‚ â”œâ”€â”€ df_bylila_con_color.csv â”‚ â”œâ”€â”€ df_categorias.csv â”‚ â”œâ”€â”€ df_con_id_forever21.csv â”‚ â”œâ”€â”€ df_con_id_vestidos.csv â”‚ â”œâ”€â”€ df_final_vestidos.csv â”‚ â”œâ”€â”€ df_forever21.csv â”‚ â”œâ”€â”€ df_forever21_final.csv â”‚ â”œâ”€â”€ df_forever21_sin_stock.csv â”‚ â”œâ”€â”€ df_ladypipa.csv â”‚ â””â”€â”€ df_marcas.csv â”œâ”€â”€ scraping â”‚ â”œâ”€â”€ links_ladypipa.json â”‚ â””â”€â”€ links_nbl.json â”œâ”€â”€ graficos â”‚ â”œâ”€â”€ 1-vestidos_por_marca.png â”‚ â”œâ”€â”€ 2-tallas_por_marca.png â”‚ â”œâ”€â”€ 3-media_precios_marca.png â”‚ â”œâ”€â”€ 4-precio_por_talla.png â”‚ â”œâ”€â”€ 5-porcentaje_talla_por_categoria.png â”‚ â””â”€â”€ 6-normal_vestidos_por_talla.png â”œâ”€â”€ imagenes â”‚ â”œâ”€â”€ portada-1.png â”‚ â””â”€â”€ portada.png â”œâ”€â”€ notebooks â”‚ â”œâ”€â”€ 1-api_asos.ipynb â”‚ â”œâ”€â”€ 2-api_forever21.ipynb â”‚ â”œâ”€â”€ 3-scraping_lila.ipynb â”‚ â”œâ”€â”€ 4-scraping_ladypipa.ipynb â”‚ â”œâ”€â”€ 5-limpieza.ipynb â”‚ â”œâ”€â”€ 6-creacion_insercion_bbdd.ipynb â”‚ â”œâ”€â”€ 7-analisis.ipynb â”‚ â””â”€â”€ asos-vieja.ipynb â””â”€â”€ src â”œâ”€â”€ dic.py â”œâ”€â”€ funciones_analisis.py â”œâ”€â”€ funciones_api.py â”œâ”€â”€ funciones_bbdd.py â”œâ”€â”€ funciones_scraping.py â””â”€â”€ queries.py