# 游녱 Vestidos para Cuerpos Reales 

![Descripci칩n de la imagen](imagenes/portada.png)

# 游눠 Introducci칩n al proyecto 

Hace unos meses comenc칠 con muchisima ilusi칩n la busqueda del vestido perfecto para mi graduaci칩n, sin embargo, tras ojear unas cu치ntas webs y visitar la mayor칤a de las tiendas de mi ciudad me di cuenta de algo, o los fabricantes se hab칤an olvidado de mi talla o no encajaba en los patrones de la moda normativa. Me considero una mujer dentro de la media espa침ola, ni muy alta ni muy baja, ni muy delgada ni muy gorda, simplemnete en la media, o lo que yo pensaba que era la media. Por lo que investigu칠 un poco qu칠 estaba pasando con las tallas y descubr칤 que no estaba sola, que miles de mujeres se encontraban en la misma situaci칩n que yo. Me le칤 numerosos art칤culo hablando del tema, todos mencionaban una misma fuente, la Asecom (La Asociaci칩n de empresas de confecci칩n y moda de la comunidad de Madrid), la cual realiz칩 un estudio en el que asegura que las tallas 42 y 44 son las que m치s se venden en Espa침a, pese a que los escaparates no muestran precisamente a maniqu칤es con dichas medidas.

Finalmente encontr칠 mi vestido, pero me cost칩. Por lo que unos meses m치s tarde y ya con las herramientas y conocimientos necesarios planteo este proyecto abordando un problema real: **쯉on los vestidos de hoy para las mujeres del hoy?**

Se inicia este proyecto a peque침a escala, analizando nueve de las marcas que visit칠 hace unos meses en busca de vestido las cuales son: Mango, Forever21, Ghospell, Jaded Rose, Love Triangle, NA-KD, Vero Moda, Natural by Lila y Ladypipa. Siendo estas tiendas muy diversas a pque침as y gran escala tanto espa침olas como europeas o americanas.


# 游꿢 Objetivo 

El objetivo fundamental entorno al cual se desarrolla este proyecto consiste en descubrir si las marcas objeto de nuestro estudio ofrecen diversidad de tallas y suficiente oferta de tallas L y XL, las cuales son las m치s consumidas en Espa침a. Para ello almacenaremos todos los datos recabados y observaremos y analizaremos las siguientes cuestiones:

- La ditribuci칩n de vestidos por marca.
- La distribuci칩n de prendas por talla para cada marca.
- El precio medio y mediano para los vestidos de cada marca.
- El precio medio y mediano por tallas.
- El porcentaje de prendas por tallas para distintos tipos de vestidos.
- La distribuci칩n de vestidos por tallas.

Adem치s, de la marca Forever21 hemos conseguido obtener el stock para cada vestido y talla por lo que tambi칠n ser치n analizados estos datos.

# 游늬 Estructura

- El proyecto consiste en la implementaci칩n de una ETL y un posterioir an치lisis. Se ha estructurado en una primera fase de extracci칩n de datos. Los datos se han obtenido mediante APIs y scraping de dos p치ginas web. Las APIs son: [Asos](https://rapidapi.com/DataCrawler/api/asos10) y [Forever21](https://rapidapi.com/apidojo/api/forever21) y las p치ginas web: [NaturalByLila](https://naturalbylila.com/) y [Ladypipa](https://ladypipa.com/). 

    - La obtenci칩n de informaci칩n de las APIs se ha llevado a cabo en los notebooks 1 y 2 que se pueden encontrar en la carpeta `notebooks` apoyandose en el archivo de `funciones_api.py` de la carpeta `src`. Los datos extraidos han sido almacenados en la carpeta `datos` dentro de `api_asos` y `api_forever21`.

    - El scraping de las webs se puede encontrar en los notebooks `3-scraping_lila.ipynb` y `4-scraping_ladypipa.ipynb` y las funciones de apoyo en la carpeta `src` en el archivo `funciones_craping.py`. 

- Una vez etraidos todos los datos pasamos a la segunda fase de la ETL que es la transformaci칩n y limpieza, llevada a cabo en el notebook `5-limpieza.iynb`. En esta fase limpiamos las columnas de cada dataframe a침adiendo nuevas columnas o quitando alguna existente y normalizando los datos para poder unificar todos los datos obtenidos en la primera fase.

- El 칰ltimo paso es la creaci칩n y carga de los datos en una base de datos SQL, este paso se ejecuta en el notebook `6-creacion_insercion_bbdd.ipynb` apoyandose en las funciones del archivo `funciones_bbdd.py` y `queries.py`. Se crea la base de datos, las tablas y se realizan las consultas necesarias para insertar todos los datos en nuestra base de datos. 

- Finamente, pasamos a la fase del an치lisis mediante consultas SQL. En esta fase extraeremos la informaci칩n relevante para analizar las propuestas planteadas como objetivo y mostrar gr치ficas para observar de una forma m치s visual los resultados. Toda esta informaci칩n se puede encontrar en el notebook `7-analisis.ipynb` apoyado en las funciones de `funciones_analisis.py`.

Por lo tanto, el contenido de las carpetas es el siguiente:

- **datos**: Contiene los datos obtenidos de las APIs y el scraping.
  - **api_asos**: Datos obtenidos de la API de ASOS.
  - **api_forever21**: Datos obtenidos de la API de Forever21.
  - **scraping**: Datos obtenidos mediante t칠cnicas de scraping.
  - **dataframes**: Donde se almacenan los dataframes limpios de cada marca.

- **graficos**: Contiene las visualizaciones generadas a partir de los datos.

- **imagenes**: Im치genes utilizadas en el proyecto.

- **notebooks**: Jupyter notebooks con el c칩digo y an치lisis del proyecto.

- **src**: Scripts de Python con funciones de apoyo para los noteboks.