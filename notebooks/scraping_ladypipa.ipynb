{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping de Lapypipa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro objetivo consiste en escrapear la pagina de vestidos de Ladypipa para ello usaremos tanto Selenium como Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from src import funciones_scraping as fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con Selenium accedemos a la página principal de vestidos y sacamos todos los links a los que posterioirmente vamos a acceder. Estos links los almacenamos dentro de la carpeta datos para tenerlos guardados y solo tener que ejecutar una vez la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_ladypipa = fs.obtencion_links_ladypipa()\n",
    "\n",
    "with open(\"../datos/scraping/links_ladypipa.json\", \"w\") as archivo_json:\n",
    "    json.dump(links_ladypipa, archivo_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mediande BeautifulSoup iremos recabando de cada vestido la información necesaria para crear el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datos/scraping/links_ladypipa.json\", \"r\") as archivo_json:\n",
    "    links_ladypipa = json.load(archivo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_vestido = {\n",
    "#         \"nombre\" : [],\n",
    "#         \"marca\" : [],\n",
    "#         \"precio\" : [],\n",
    "#         \"talla\" : [],\n",
    "#         \"categoria\" :[]\n",
    "#         }\n",
    "\n",
    "# for url in links_ladypipa:\n",
    "#     res = requests.get(url)\n",
    "#     if res.status_code != 200:\n",
    "#         print(url)\n",
    "\n",
    "#     sopa = BeautifulSoup(res.content, \"html.parser\")\n",
    "#     nombre = sopa.find(\"div\", {\"class\":\"product-info__title\"}).text.replace(\"\\n\",\"\").strip()\n",
    "#     marca = \"Ladypipa\"\n",
    "\n",
    "#     # Extraemos el precio\n",
    "#     patron = r\"(\\d+(?:,\\d{1,2})?)\\s*€\"\n",
    "#     resultado = re.search(patron, sopa.find(\"sale-price\").text)\n",
    "#     precio = resultado.group(1)\n",
    "\n",
    "#     # Buscamos en la descripcion cómo es el vestido para asignarle una categoría\n",
    "#     desc = sopa.select(\"div.prose p\")[2].text\n",
    "\n",
    "#     patron = r'\\b(largo|midi|corto|maxi|mini)\\b'\n",
    "#     coincidencias = re.findall(patron, desc)\n",
    "#     categoria = coincidencias[0]\n",
    "\n",
    "#     # Sacamos las tallas disponibles\n",
    "#     lista_tallas=[]\n",
    "#     contenedor_tallas = sopa.find(\"div\", {\"class\":\"form-control\"}).find(\"select\").find_all('option')\n",
    "#     for talla in contenedor_tallas:\n",
    "#         if not talla.has_attr('disabled'):\n",
    "#             lista_tallas.append(talla.text.split()[0])\n",
    "#     lista_tallas\n",
    "\n",
    "#     for elem in lista_tallas:\n",
    "#         dic_vestido[\"nombre\"].append(nombre)\n",
    "#         dic_vestido[\"marca\"].append(marca)\n",
    "#         dic_vestido[\"precio\"].append(precio)\n",
    "#         dic_vestido[\"talla\"].append(elem)\n",
    "#         dic_vestido[\"categoria\"].append(categoria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_vestido = fs.extraccion_info_ladypipa(links_ladypipa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lady_pipa = pd.DataFrame(dic_vestido)\n",
    "df_lady_pipa.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
